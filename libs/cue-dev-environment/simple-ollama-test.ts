/**
 * Simple Ollama Test Script
 * Tests basic connectivity and model functionality with available models
 */

import axios from 'axios';
import chalk from 'chalk';
import { config } from 'dotenv';

config({ path: '../../.env.development' });

interface OllamaModel {
  name: string;
  size?: number;
  digest?: string;
  modified_at?: string;
}

class SimpleOllamaTest {
  private host: string;
  private availableModels: OllamaModel[] = [];

  constructor() {
    this.host = process.env.OLLAMA_HOST || 'http://localhost:11434';
  }

  async testConnection(): Promise<boolean> {
    try {
      console.log(chalk.cyan('üîç Testing Ollama connection...'));
      const response = await axios.get(`${this.host}/api/tags`, { timeout: 5000 });
      console.log(chalk.green('‚úÖ Connected to Ollama successfully'));
      
      this.availableModels = response.data.models || [];
      return true;
    } catch (error: any) {
      console.log(chalk.red('‚ùå Failed to connect to Ollama:'));
      console.log(chalk.gray(`   Host: ${this.host}`));
      console.log(chalk.gray(`   Error: ${error.message}`));
      return false;
    }
  }

  displayAvailableModels(): void {
    console.log(chalk.cyan('\nüìã Available Models:'));
    if (this.availableModels.length === 0) {
      console.log(chalk.yellow('  No models found'));
      return;
    }

    this.availableModels.forEach((model, index) => {
      const size = model.size ? this.formatBytes(model.size) : 'unknown size';
      console.log(chalk.white(`  ${index + 1}. ${model.name} (${size})`));
    });
  }

  async testModelGeneration(modelName: string): Promise<boolean> {
    try {
      console.log(chalk.blue(`\nü§ñ Testing ${modelName}...`));
      
      const testPrompt = 'Hello! Please respond with "CUE Development Environment Ready" if you can assist with TypeScript development.';
      
      const startTime = Date.now();
      const response = await axios.post(`${this.host}/api/generate`, {
        model: modelName,
        prompt: testPrompt,
        stream: false,
        options: {
          temperature: 0.7,
          max_tokens: 100
        }
      }, { timeout: 30000 });

      const responseTime = Date.now() - startTime;
      const result = response.data.response;

      console.log(chalk.green(`‚úÖ ${modelName} responded in ${responseTime}ms`));
      console.log(chalk.gray(`   Response: ${result.substring(0, 100)}${result.length > 100 ? '...' : ''}`));
      
      // Check if response indicates readiness
      const isReady = result.toLowerCase().includes('ready') || 
                     result.toLowerCase().includes('assist') ||
                     result.toLowerCase().includes('help') ||
                     result.toLowerCase().includes('development');

      if (isReady) {
        console.log(chalk.green(`   ‚úÖ Model appears ready for development assistance`));
      } else {
        console.log(chalk.yellow(`   ‚ö†Ô∏è  Model response unclear, but functional`));
      }

      return true;

    } catch (error: any) {
      console.log(chalk.red(`‚ùå ${modelName} test failed:`));
      console.log(chalk.gray(`   Error: ${error.message}`));
      return false;
    }
  }

  async testCodeGeneration(modelName: string): Promise<void> {
    try {
      console.log(chalk.blue(`\nüî® Testing code generation with ${modelName}...`));
      
      const codePrompt = `Create a simple TypeScript function that validates if a number is prime. Include error handling and JSDoc comments.`;
      
      const startTime = Date.now();
      const response = await axios.post(`${this.host}/api/generate`, {
        model: modelName,
        prompt: codePrompt,
        stream: false,
        options: {
          temperature: 0.3,
          max_tokens: 500
        }
      }, { timeout: 60000 });

      const responseTime = Date.now() - startTime;
      const result = response.data.response;

      console.log(chalk.green(`‚úÖ Code generation completed in ${responseTime}ms`));
      console.log(chalk.cyan('\nüìù Generated Code:'));
      console.log(chalk.white(result));

    } catch (error: any) {
      console.log(chalk.red(`‚ùå Code generation test failed: ${error.message}`));
    }
  }

  async runComprehensiveTest(): Promise<void> {
    console.log(chalk.cyan('üöÄ Starting Comprehensive Ollama Test...'));
    console.log(chalk.gray('='.repeat(60)));

    // Test connection
    const connected = await this.testConnection();
    if (!connected) {
      console.log(chalk.red('\n‚ùå Cannot proceed - Ollama connection failed'));
      console.log(chalk.yellow('üí° Make sure Ollama is running: ollama serve'));
      return;
    }

    // Display available models
    this.displayAvailableModels();

    if (this.availableModels.length === 0) {
      console.log(chalk.red('\n‚ùå No models available for testing'));
      console.log(chalk.yellow('üí° Pull a model first: ollama pull llama3.2:3b'));
      return;
    }

    // Test each available model
    let workingModels = 0;
    let bestModel = '';
    let bestTime = Infinity;

    console.log(chalk.cyan('\nüß™ Testing Model Functionality...'));
    
    for (const model of this.availableModels) {
      const startTime = Date.now();
      const success = await this.testModelGeneration(model.name);
      const responseTime = Date.now() - startTime;
      
      if (success) {
        workingModels++;
        if (responseTime < bestTime) {
          bestTime = responseTime;
          bestModel = model.name;
        }
      }
    }

    // Summary
    console.log(chalk.cyan('\nüìä Test Summary:'));
    console.log(chalk.white(`  Models tested: ${this.availableModels.length}`));
    console.log(chalk.white(`  Working models: ${workingModels}`));
    if (bestModel) {
      console.log(chalk.white(`  Fastest model: ${bestModel} (${bestTime}ms)`));
      
      // Test code generation with best model
      await this.testCodeGeneration(bestModel);
    }

    if (workingModels > 0) {
      console.log(chalk.green('\nüéâ Ollama integration is working!'));
      console.log(chalk.cyan('üéØ Ready for CUE development with AI assistance'));
    } else {
      console.log(chalk.red('\n‚ùå No working models found'));
    }
  }

  private formatBytes(bytes: number): string {
    const gb = bytes / (1024 * 1024 * 1024);
    if (gb >= 1) return `${gb.toFixed(1)} GB`;
    
    const mb = bytes / (1024 * 1024);
    return `${mb.toFixed(0)} MB`;
  }
}

// Run the test if this file is executed directly
async function runTest() {
  const tester = new SimpleOllamaTest();
  await tester.runComprehensiveTest();
}

if (require.main === module) {
  runTest().catch(console.error);
}

export { SimpleOllamaTest };